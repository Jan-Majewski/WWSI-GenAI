{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hybrid Search with Elasticsearch\n",
    "\n",
    "## Overview\n",
    "This notebook demonstrates three different search approaches using Elasticsearch:\n",
    "1. **Keyword Search (BM25)** - Traditional full-text search based on term frequency and document length\n",
    "2. **Semantic Search (Vector)** - Searches based on meaning using embeddings\n",
    "3. **Hybrid Search** - Combines both approaches for optimal results\n",
    "\n",
    "We'll use the same travel company FAQ dataset and show how each approach performs differently on various queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import pandas as pd\nimport openai\nimport os\nfrom dotenv import load_dotenv\nfrom elasticsearch import Elasticsearch\nfrom elasticsearch.helpers import bulk\nimport numpy as np\nfrom typing import List, Dict, Any\nfrom tqdm.auto import tqdm\nimport warnings\nwarnings.filterwarnings('ignore')"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Navigate to project root\n",
    "os.chdir(\"..\")\n",
    "load_dotenv()\n",
    "\n",
    "# Setup OpenAI\n",
    "openai.api_key = OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "client = openai.Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Connect to Elasticsearch\n",
    "\n",
    "Make sure you have Elasticsearch running:\n",
    "```bash\n",
    "docker ps | grep elasticsearch\n",
    "```\n",
    "\n",
    "If not running, start it:\n",
    "```bash\n",
    "docker run -d --name elasticsearch -p 9200:9200 -p 9300:9300 \\\n",
    "  -e \"discovery.type=single-node\" -e \"xpack.security.enabled=false\" \\\n",
    "  -e \"ES_JAVA_OPTS=-Xms512m -Xmx512m\" \\\n",
    "  docker.elastic.co/elasticsearch/elasticsearch:8.11.0\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úó Failed to connect to Elasticsearch\n"
     ]
    }
   ],
   "source": [
    "# Connect to Elasticsearch\n",
    "# For ES 8.x with security disabled, we need to explicitly configure the client\n",
    "es = Elasticsearch(\n",
    "    ['http://localhost:9200'],\n",
    "    verify_certs=False,\n",
    "    ssl_show_warn=False,\n",
    "    request_timeout=30\n",
    ")\n",
    "\n",
    "# Verify connection\n",
    "try:\n",
    "    if es.ping():\n",
    "        print(\"‚úì Connected to Elasticsearch\")\n",
    "        info = es.info()\n",
    "        print(f\"Cluster: {info['cluster_name']}\")\n",
    "        print(f\"Version: {info['version']['number']}\")\n",
    "    else:\n",
    "        print(\"‚úó Failed to connect to Elasticsearch\")\n",
    "except Exception as e:\n",
    "    print(f\"‚úó Connection error: {e}\")\n",
    "    print(\"\\nTroubleshooting:\")\n",
    "    print(\"1. Check if Elasticsearch is running: docker ps | grep elasticsearch\")\n",
    "    print(\"2. Test with curl: curl http://localhost:9200\")\n",
    "    print(\"3. Make sure you have elasticsearch python package installed: pip install elasticsearch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Travel FAQ Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the same dataset used in the vector search notebook\n",
    "df = pd.read_json(\"data/travel_company_faq.json\")\n",
    "\n",
    "print(f\"Loaded {len(df)} FAQ items\")\n",
    "print(f\"Categories: {df['category'].unique().tolist()}\")\n",
    "print(f\"\\nSample question: {df.iloc[0]['question']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create Elasticsearch Index with Hybrid Search Support\n",
    "\n",
    "We'll create an index that supports both:\n",
    "- **Text fields** for keyword search (BM25)\n",
    "- **Dense vector fields** for semantic search\n",
    "\n",
    "The mapping defines how each field should be indexed and searched."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INDEX_NAME = \"travel_faq_hybrid\"\n",
    "\n",
    "# Define the index mapping\n",
    "mapping = {\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"question\": {\n",
    "                \"type\": \"text\",\n",
    "                \"analyzer\": \"english\"\n",
    "            },\n",
    "            \"answer\": {\n",
    "                \"type\": \"text\",\n",
    "                \"analyzer\": \"english\"\n",
    "            },\n",
    "            \"combined_text\": {\n",
    "                \"type\": \"text\",\n",
    "                \"analyzer\": \"english\"\n",
    "            },\n",
    "            \"category\": {\n",
    "                \"type\": \"keyword\"\n",
    "            },\n",
    "            \"embedding\": {\n",
    "                \"type\": \"dense_vector\",\n",
    "                \"dims\": 1536,  # OpenAI ada-002 dimension\n",
    "                \"index\": True,\n",
    "                \"similarity\": \"cosine\"\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": 1,\n",
    "        \"number_of_replicas\": 0\n",
    "    }\n",
    "}\n",
    "\n",
    "# Delete index if it exists\n",
    "if es.indices.exists(index=INDEX_NAME):\n",
    "    es.indices.delete(index=INDEX_NAME)\n",
    "    print(f\"Deleted existing index: {INDEX_NAME}\")\n",
    "\n",
    "# Create the index\n",
    "es.indices.create(index=INDEX_NAME, body=mapping)\n",
    "print(f\"‚úì Created index: {INDEX_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Generate Embeddings and Ingest Data\n",
    "\n",
    "We'll use OpenAI's `text-embedding-ada-002` model to generate embeddings for each FAQ item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def get_embedding(text: str, model: str = \"text-embedding-ada-002\") -> List[float]:\n    \"\"\"Get embedding from OpenAI API for a single text\"\"\"\n    response = client.embeddings.create(input=[text], model=model)\n    return response.data[0].embedding\n\ndef get_embeddings_batch(texts: List[str], model: str = \"text-embedding-ada-002\", batch_size: int = 100) -> List[List[float]]:\n    \"\"\"\n    Get embeddings for multiple texts in batches.\n    OpenAI allows up to 2048 texts per request, but we use smaller batches for stability.\n    \"\"\"\n    all_embeddings = []\n    \n    # Process in batches with progress bar\n    for i in tqdm(range(0, len(texts), batch_size), desc=\"Getting embeddings\", unit=\"batch\"):\n        batch = texts[i:i + batch_size]\n        response = client.embeddings.create(input=batch, model=model)\n        batch_embeddings = [item.embedding for item in response.data]\n        all_embeddings.extend(batch_embeddings)\n    \n    return all_embeddings\n\ndef prepare_documents_for_indexing(df: pd.DataFrame) -> List[Dict[str, Any]]:\n    \"\"\"\n    Prepare documents for bulk indexing.\n    Each document includes text fields and embeddings.\n    Uses batch processing for faster embedding generation.\n    \"\"\"\n    print(f\"Preparing {len(df)} documents for indexing...\")\n    \n    # Combine all texts first\n    combined_texts = []\n    for idx, row in df.iterrows():\n        combined_text = f\"Question: {row['question']}\\nAnswer: {row['answer']}\"\n        combined_texts.append(combined_text)\n    \n    # Get all embeddings in batches (much faster!)\n    embeddings = get_embeddings_batch(combined_texts)\n    \n    # Build documents with progress bar\n    documents = []\n    for idx, (row, combined_text, embedding) in enumerate(tqdm(\n        zip(df.iterrows(), combined_texts, embeddings),\n        total=len(df),\n        desc=\"Building documents\",\n        unit=\"doc\"\n    )):\n        _, row = row  # iterrows returns (index, row)\n        \n        doc = {\n            \"_index\": INDEX_NAME,\n            \"_id\": f\"faq_{idx}\",\n            \"_source\": {\n                \"question\": row[\"question\"],\n                \"answer\": row[\"answer\"],\n                \"combined_text\": combined_text,\n                \"category\": row[\"category\"],\n                \"embedding\": embedding\n            }\n        }\n        documents.append(doc)\n    \n    print(f\"‚úì Prepared {len(documents)} documents\")\n    return documents"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Prepare and index documents\nprint(\"Generating embeddings and preparing documents...\")\ndocuments = prepare_documents_for_indexing(df)\n\n# Bulk index with progress\nprint(\"\\nIndexing documents to Elasticsearch...\")\nsuccess, failed = bulk(es, documents, raise_on_error=False)\nprint(f\"‚úì Successfully indexed {success} documents\")\nif failed:\n    print(f\"‚úó Failed to index {failed} documents\")\n\n# Refresh index to make documents searchable\nes.indices.refresh(index=INDEX_NAME)\nprint(\"‚úì Index refreshed and ready for search\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify indexing\n",
    "count = es.count(index=INDEX_NAME)['count']\n",
    "print(f\"Total documents in index: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Implement Three Search Approaches\n",
    "\n",
    "### 5.1 Keyword Search (BM25)\n",
    "Traditional full-text search using BM25 algorithm. Good for:\n",
    "- Exact keyword matches\n",
    "- Technical terms\n",
    "- Specific phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def keyword_search(query: str, top_k: int = 5) -> List[Dict[str, Any]]:\n    \"\"\"\n    Keyword search using BM25.\n    Searches across question, answer, and combined_text fields.\n    \"\"\"\n    search_query = {\n        \"query\": {\n            \"multi_match\": {\n                \"query\": query,\n                \"fields\": [\"question^2\", \"answer\", \"combined_text\"],  # Boost question field\n                \"type\": \"best_fields\"\n            }\n        },\n        \"size\": top_k\n    }\n    \n    response = es.search(index=INDEX_NAME, body=search_query)\n    \n    results = []\n    for hit in response['hits']['hits']:\n        results.append({\n            \"question\": hit[\"_source\"][\"question\"],\n            \"answer\": hit[\"_source\"][\"answer\"],\n            \"category\": hit[\"_source\"][\"category\"],\n            \"score\": hit[\"_score\"],\n            \"search_type\": \"keyword\"\n        })\n    \n    return results"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Semantic Search (Vector Similarity)\n",
    "Searches based on meaning using embeddings. Good for:\n",
    "- Conceptual similarity\n",
    "- Paraphrased queries\n",
    "- Finding related content even with different words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def semantic_search(query: str, top_k: int = 5) -> List[Dict[str, Any]]:\n    \"\"\"\n    Semantic search using vector similarity.\n    Converts query to embedding and finds most similar documents.\n    \"\"\"\n    # Generate query embedding\n    query_embedding = get_embedding(query)\n    \n    search_query = {\n        \"knn\": {\n            \"field\": \"embedding\",\n            \"query_vector\": query_embedding,\n            \"k\": top_k,\n            \"num_candidates\": 100\n        },\n        \"_source\": [\"question\", \"answer\", \"category\"],\n        \"size\": top_k\n    }\n    \n    response = es.search(index=INDEX_NAME, **search_query)\n    \n    results = []\n    for hit in response['hits']['hits']:\n        results.append({\n            \"question\": hit[\"_source\"][\"question\"],\n            \"answer\": hit[\"_source\"][\"answer\"],\n            \"category\": hit[\"_source\"][\"category\"],\n            \"score\": hit[\"_score\"],\n            \"search_type\": \"semantic\"\n        })\n    \n    return results"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Hybrid Search (Combined)\n",
    "Combines both keyword and semantic search with adjustable weights. Best of both worlds:\n",
    "- Balances exact matches with conceptual similarity\n",
    "- More robust across different query types\n",
    "- Can be tuned for specific use cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hybrid_search(query: str, top_k: int = 5, keyword_weight: float = 0.5, semantic_weight: float = 0.5) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Hybrid search combining keyword (BM25) and semantic (vector) search.\n",
    "    \n",
    "    Args:\n",
    "        query: Search query\n",
    "        top_k: Number of results to return\n",
    "        keyword_weight: Weight for keyword search (0-1)\n",
    "        semantic_weight: Weight for semantic search (0-1)\n",
    "    \"\"\"\n",
    "    # Generate query embedding for semantic search\n",
    "    query_embedding = get_embedding(query)\n",
    "    \n",
    "    # Elasticsearch hybrid query using bool should with knn\n",
    "    search_query = {\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "                \"should\": [\n",
    "                    # Keyword search component\n",
    "                    {\n",
    "                        \"multi_match\": {\n",
    "                            \"query\": query,\n",
    "                            \"fields\": [\"question^2\", \"answer\", \"combined_text\"],\n",
    "                            \"type\": \"best_fields\",\n",
    "                            \"boost\": keyword_weight\n",
    "                        }\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        },\n",
    "        \"knn\": {\n",
    "            \"field\": \"embedding\",\n",
    "            \"query_vector\": query_embedding,\n",
    "            \"k\": top_k,\n",
    "            \"num_candidates\": 100,\n",
    "            \"boost\": semantic_weight\n",
    "        },\n",
    "        \"size\": top_k,\n",
    "        \"_source\": [\"question\", \"answer\", \"category\"]\n",
    "    }\n",
    "    \n",
    "    response = es.search(index=INDEX_NAME, body=search_query)\n",
    "    \n",
    "    results = []\n",
    "    for hit in response['hits']['hits']:\n",
    "        results.append({\n",
    "            \"question\": hit[\"_source\"][\"question\"],\n",
    "            \"answer\": hit[\"_source\"][\"answer\"],\n",
    "            \"category\": hit[\"_source\"][\"category\"],\n",
    "            \"score\": hit[\"_score\"],\n",
    "            \"search_type\": \"hybrid\"\n",
    "        })\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Comparison Framework\n",
    "\n",
    "Let's create functions to compare all three search approaches side-by-side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def compare_search_approaches(query: str, top_k: int = 3):\n    \"\"\"\n    Compare all three search approaches for a given query.\n    \"\"\"\n    print(\"=\" * 100)\n    print(f\"Query: '{query}'\")\n    print(\"=\" * 100)\n    \n    # Run all three searches\n    try:\n        keyword_results = keyword_search(query, top_k)\n        semantic_results = semantic_search(query, top_k)\n        hybrid_results = hybrid_search(query, top_k)\n    except Exception as e:\n        print(f\"\\n‚úó Search error: {e}\")\n        print(f\"Error type: {type(e).__name__}\")\n        return\n    \n    # Check if we got results\n    if not keyword_results or not semantic_results or not hybrid_results:\n        print(\"\\n‚úó One or more search methods returned no results\")\n        print(f\"Keyword: {len(keyword_results)} results\")\n        print(f\"Semantic: {len(semantic_results)} results\")\n        print(f\"Hybrid: {len(hybrid_results)} results\")\n        return\n    \n    # Get the minimum number of results across all methods\n    actual_k = min(len(keyword_results), len(semantic_results), len(hybrid_results))\n    \n    if actual_k < top_k:\n        print(f\"\\n‚ö†Ô∏è  Requested {top_k} results, but only {actual_k} available across all methods\")\n    \n    # Display results side by side\n    for i in range(actual_k):\n        print(f\"\\n{'‚îÄ' * 100}\")\n        print(f\"RANK #{i+1}\")\n        print(f\"{'‚îÄ' * 100}\")\n        \n        # Keyword results\n        print(f\"\\nüîç KEYWORD SEARCH (BM25) - Score: {keyword_results[i]['score']:.4f}\")\n        print(f\"   Category: {keyword_results[i]['category']}\")\n        print(f\"   Q: {keyword_results[i]['question']}\")\n        print(f\"   A: {keyword_results[i]['answer'][:150]}...\")\n        \n        # Semantic results\n        print(f\"\\nüß† SEMANTIC SEARCH (Vector) - Score: {semantic_results[i]['score']:.4f}\")\n        print(f\"   Category: {semantic_results[i]['category']}\")\n        print(f\"   Q: {semantic_results[i]['question']}\")\n        print(f\"   A: {semantic_results[i]['answer'][:150]}...\")\n        \n        # Hybrid results\n        print(f\"\\n‚ö° HYBRID SEARCH (Combined) - Score: {hybrid_results[i]['score']:.4f}\")\n        print(f\"   Category: {hybrid_results[i]['category']}\")\n        print(f\"   Q: {hybrid_results[i]['question']}\")\n        print(f\"   A: {hybrid_results[i]['answer'][:150]}...\")\n    \n    print(f\"\\n{'=' * 100}\\n\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def create_comparison_table(query: str, top_k: int = 5) -> pd.DataFrame:\n    \"\"\"\n    Create a comparison table showing which documents each search method retrieves.\n    \"\"\"\n    try:\n        keyword_results = keyword_search(query, top_k)\n        semantic_results = semantic_search(query, top_k)\n        hybrid_results = hybrid_search(query, top_k)\n    except Exception as e:\n        print(f\"Search error: {e}\")\n        return pd.DataFrame()\n    \n    # Get the minimum number of results\n    actual_k = min(len(keyword_results), len(semantic_results), len(hybrid_results), top_k)\n    \n    if actual_k == 0:\n        print(\"No results returned from searches\")\n        return pd.DataFrame()\n    \n    # Create comparison dataframe\n    comparison_data = []\n    \n    for i in range(actual_k):\n        comparison_data.append({\n            \"Rank\": i + 1,\n            \"Keyword_Question\": keyword_results[i]['question'][:60] + \"...\",\n            \"Keyword_Score\": f\"{keyword_results[i]['score']:.3f}\",\n            \"Semantic_Question\": semantic_results[i]['question'][:60] + \"...\",\n            \"Semantic_Score\": f\"{semantic_results[i]['score']:.3f}\",\n            \"Hybrid_Question\": hybrid_results[i]['question'][:60] + \"...\",\n            \"Hybrid_Score\": f\"{hybrid_results[i]['score']:.3f}\"\n        })\n    \n    df_comparison = pd.DataFrame(comparison_data)\n    return df_comparison"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Test Queries - Showcasing Differences\n",
    "\n",
    "Let's test with queries that highlight the strengths of each approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 1: Exact Keyword Match\n",
    "Query with specific keywords that appear in documents.\n",
    "**Expected:** Keyword search should perform best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_search_approaches(\"baggage allowance\", top_k=3)"
   ]
  },
  {
   "cell_type": "code",
   "source": "# Test each search method individually to diagnose issues\ntest_query = \"lost luggage compensation\"\n\nprint(\"Testing individual search methods:\\n\")\n\ntry:\n    print(\"1. Keyword search...\")\n    kw_results = keyword_search(test_query, top_k=3)\n    print(f\"   ‚úì Returned {len(kw_results)} results\")\nexcept Exception as e:\n    print(f\"   ‚úó Error: {e}\")\n\ntry:\n    print(\"\\n2. Semantic search...\")\n    sem_results = semantic_search(test_query, top_k=3)\n    print(f\"   ‚úì Returned {len(sem_results)} results\")\nexcept Exception as e:\n    print(f\"   ‚úó Error: {e}\")\n\ntry:\n    print(\"\\n3. Hybrid search...\")\n    hyb_results = hybrid_search(test_query, top_k=3)\n    print(f\"   ‚úì Returned {len(hyb_results)} results\")\nexcept Exception as e:\n    print(f\"   ‚úó Error: {e}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 2: Semantic Query (Different Words, Same Meaning)\n",
    "Query using different terminology than what's in the documents.\n",
    "**Expected:** Semantic search should perform best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_search_approaches(\"What happens if I need medical help while traveling?\", top_k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 3: Mixed Query\n",
    "Query that benefits from both keyword matching and semantic understanding.\n",
    "**Expected:** Hybrid search should perform best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_search_approaches(\"lost luggage compensation\", top_k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 4: Specific Term\n",
    "Technical or specific term that should match exactly.\n",
    "**Expected:** Keyword search advantage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_search_approaches(\"vegetarian food options\", top_k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 5: Conceptual Query\n",
    "Asking about a concept without using exact terminology.\n",
    "**Expected:** Semantic search advantage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_search_approaches(\"getting money back for cancelled trip\", top_k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 6: Natural Language Question\n",
    "Full natural language question.\n",
    "**Expected:** Hybrid search should balance both approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_search_approaches(\"Can I change my booking dates after I've already confirmed?\", top_k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Comparison Tables\n",
    "\n",
    "Let's create comparison tables to see which documents each method retrieves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: Keyword-friendly query\n",
    "print(\"Query: 'baggage allowance'\\n\")\n",
    "df_comp1 = create_comparison_table(\"baggage allowance\", top_k=5)\n",
    "display(df_comp1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2: Semantic-friendly query\n",
    "print(\"Query: 'What happens if I need medical help while traveling?'\\n\")\n",
    "df_comp2 = create_comparison_table(\"What happens if I need medical help while traveling?\", top_k=5)\n",
    "display(df_comp2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Tuning Hybrid Search Weights\n",
    "\n",
    "The hybrid search can be tuned by adjusting the weights between keyword and semantic components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_hybrid_weights(query: str, top_k: int = 3):\n",
    "    \"\"\"\n",
    "    Compare hybrid search with different weight configurations.\n",
    "    \"\"\"\n",
    "    print(f\"Query: '{query}'\\n\")\n",
    "    \n",
    "    weight_configs = [\n",
    "        (0.8, 0.2, \"Keyword-heavy\"),\n",
    "        (0.5, 0.5, \"Balanced\"),\n",
    "        (0.2, 0.8, \"Semantic-heavy\")\n",
    "    ]\n",
    "    \n",
    "    for kw_weight, sem_weight, label in weight_configs:\n",
    "        print(f\"\\n{'‚îÄ' * 80}\")\n",
    "        print(f\"{label} (keyword={kw_weight}, semantic={sem_weight})\")\n",
    "        print(f\"{'‚îÄ' * 80}\")\n",
    "        \n",
    "        results = hybrid_search(query, top_k, keyword_weight=kw_weight, semantic_weight=sem_weight)\n",
    "        \n",
    "        for i, result in enumerate(results):\n",
    "            print(f\"\\n{i+1}. [Score: {result['score']:.4f}] {result['question']}\")\n",
    "            print(f\"   Category: {result['category']}\")\n",
    "    \n",
    "    print(f\"\\n{'=' * 80}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_hybrid_weights(\"lost luggage compensation\", top_k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Key Takeaways\n",
    "\n",
    "### When to use each approach:\n",
    "\n",
    "#### üîç Keyword Search (BM25)\n",
    "**Best for:**\n",
    "- Exact keyword matches\n",
    "- Technical terms and jargon\n",
    "- Known-item searches\n",
    "- Fast performance needs\n",
    "\n",
    "**Limitations:**\n",
    "- Doesn't understand synonyms or paraphrases\n",
    "- Misses semantically similar content with different words\n",
    "- Sensitive to spelling and exact phrasing\n",
    "\n",
    "#### üß† Semantic Search (Vector)\n",
    "**Best for:**\n",
    "- Conceptual similarity\n",
    "- Paraphrased queries\n",
    "- Questions in natural language\n",
    "- Finding related content across different terminology\n",
    "\n",
    "**Limitations:**\n",
    "- Can miss exact matches if semantically distant\n",
    "- More computationally expensive\n",
    "- May return conceptually similar but contextually wrong results\n",
    "\n",
    "#### ‚ö° Hybrid Search (Combined)\n",
    "**Best for:**\n",
    "- Production systems with diverse queries\n",
    "- When you want robustness across query types\n",
    "- Balancing precision and recall\n",
    "- Most real-world use cases\n",
    "\n",
    "**Considerations:**\n",
    "- Requires tuning weights for your specific use case\n",
    "- More complex to implement and debug\n",
    "- Higher computational cost than keyword-only\n",
    "\n",
    "### General Recommendations:\n",
    "1. Start with hybrid search (50/50 weights) as a baseline\n",
    "2. Analyze your query patterns and tune weights accordingly\n",
    "3. Use keyword-heavy weights (0.7/0.3) for technical domains\n",
    "4. Use semantic-heavy weights (0.3/0.7) for conversational queries\n",
    "5. Always evaluate on your specific dataset and use case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Cleanup\n",
    "\n",
    "Optional: Clean up the index after experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to delete the index\n",
    "# es.indices.delete(index=INDEX_NAME)\n",
    "# print(f\"Deleted index: {INDEX_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "1. **Custom Queries**: Try your own queries and observe which search method works best\n",
    "2. **Weight Tuning**: Experiment with different hybrid search weights for specific query types\n",
    "3. **Field Boosting**: Modify the keyword search to boost different fields (question vs answer)\n",
    "4. **Custom Scoring**: Implement a custom scoring function that considers category matches\n",
    "5. **Evaluation Metrics**: Create relevance judgments and calculate precision/recall for each method"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}